
<div id="TOC">
<ul>
<li><a href="#intro" id="toc-intro">Intro</a>
<ul>
<li><a href="#example" id="toc-example">Example</a></li>
</ul></li>
<li><a href="#assumptions" id="toc-assumptions">Assumptions</a></li>
<li><a href="#hypothesis" id="toc-hypothesis">Hypothesis</a></li>
<li><a href="#manova-test-statistics" id="toc-manova-test-statistics">MANOVA Test Statistics</a></li>
<li><a href="#experiment" id="toc-experiment">Experiment</a>
<ul>
<li><a href="#data-description" id="toc-data-description">Data Description</a></li>
<li><a href="#hypothesis-1" id="toc-hypothesis-1">Hypothesis</a></li>
<li><a href="#manova" id="toc-manova">MANOVA</a></li>
</ul></li>
</ul>
</div>

<hr />
<div id="intro" class="section level1">
<h1>Intro</h1>
<p>MANOVA (Multivariate analysis of variance) is an extension of ANOVA (Analysis of Variance) technique, which is used to compare means across different groups for a single dependent variable. In MANOVA, the dependent variables are correlated, and the analysis takes into account their relationships to provide a more comprehensive understanding of the effects of the independent variables. If you have only a single dependent variable, then MANOVA is not required. Regular ANOVA would be more appropriate in such cases.</p>
<p>Although separate F tests could be computed for each outcome variable, multiple
hypothesis testing would result in an increased likelihood of at least one Type I
error. In addition, because multiple outcome variables are likely to be correlated, the structure underlying the system of outcomes would be ignored with separate tests and statistical power could be decreased. A more appropriate way to examine two or more outcome variables would be to take a multivariate approach.<span class="math inline">\(^6\)</span></p>
<div id="example" class="section level2">
<h2>Example</h2>
<p>For example, if you want to determine if the height of individuals varies across different age groups, ANOVA would be suitable since you have a single dependent variable (height).</p>
<p>However, if you have multiple dependent variables that are related to the same set of independent variables, then using MANOVA would be advantageous. For instance, suppose you have data on the height, weight, and body fat percentage of individuals, and you want to investigate if these variables differ based on different exercise routines. In this scenario, MANOVA would be appropriate as you have multiple dependent variables (height, weight, and body fat percentage) that are of interest and are potentially influenced by the independent variable (exercise routine).</p>
</div>
</div>
<div id="assumptions" class="section level1">
<h1>Assumptions</h1>
<ol style="list-style-type: decimal">
<li>The dependent variables are assumed to follow a multivariate normal distribution. This assumption is important for the validity of the statistical tests used in MANOVA.<br />
</li>
<li>The observations should be independent of each other.<br />
</li>
<li>There should be no multivariate outliers in the dependent variables.<br />
</li>
<li>The dependent variables are linearly related.</li>
</ol>
</div>
<div id="hypothesis" class="section level1">
<h1>Hypothesis</h1>
<p><span class="math inline">\(H_0:\)</span> μ1 = ··· = μk against <span class="math inline">\(H_1:\)</span> not all μi’s are the same.<span class="math inline">\(^3\)</span><br />
or,<br />
<span class="math inline">\(H_0:\)</span> Group mean vectors are all equal to one another.<br />
<span class="math inline">\(H_1:\)</span> At least one pair of treatments is different on at least one variable.</p>
</div>
<div id="manova-test-statistics" class="section level1">
<h1>MANOVA Test Statistics</h1>
<ol style="list-style-type: decimal">
<li>Wilk’s Lambda: <span class="math inline">\(\Lambda^* = \dfrac{|\mathbf{E}|}{|\mathbf{H+E}|}\)</span><br />
</li>
<li>Hotelling-Lawley Trace: <span class="math inline">\(T^2_0 = trace(\mathbf{HE}^{-1})\)</span><br />
</li>
<li>Pillai Trace: <span class="math inline">\(V = trace(\mathbf{H(H+E)^{-1}})\)</span><br />
</li>
<li>Roy’s Maximum Root: Largest eigenvalue of <span class="math inline">\(HE^{-1}\)</span></li>
</ol>
<p>The power functions of these tests depend on the eigen values. Mardia (1971) has shown that Pillai’s test is robust to nonnormality so long as the distribution is symmetrc, John (1967) has shown that under some conditions, Pillai’s test is also locally most powerful. <span class="math inline">\(^7\)</span></p>
</div>
<div id="experiment" class="section level1">
<h1>Experiment</h1>
<div id="data-description" class="section level2">
<h2>Data Description</h2>
<p>The data is from an experiment in which the optimal conditions for growth and product formation were determined for a bacterial strain in a broth with a certain carbon source. Two different nitrogen sources (yeast extract and ammonium chloride) and three different incubation temperatures (30, 35, 37) were evaluated. Bacterial growth was evaluated after 24 hours using dry cell weight (in mg/ml) and optical density at 600 nm. The yield of a desired fermentation product was determined using gas chromatography and expressed in mM. <span class="math inline">\(^4\)</span></p>
<pre class="r"><code># reading data
data &lt;- read.table(&quot;data/MANOVA.txt&quot;, header = T, sep = &quot;\t&quot;)

library(tidyverse)
data &lt;- data %&gt;% mutate(across(c(&quot;Temperature&quot;,&quot;N.source&quot;), factor))
summary(data)</code></pre>
<pre><code>#   Experiment        Temperature              N.source     Replica     
#  Length:120         30:40       ammonium chloride:60   Min.   : 1.00  
#  Class :character   35:40       yeast extract    :60   1st Qu.: 5.75  
#  Mode  :character   37:40                              Median :10.50  
#                                                        Mean   :10.50  
#                                                        3rd Qu.:15.25  
#                                                        Max.   :20.00  
#    Dry.weight     Optical.density Product.yield  
#  Min.   : 1.670   Min.   :0.210   Min.   : 8.40  
#  1st Qu.: 4.805   1st Qu.:1.770   1st Qu.:41.90  
#  Median : 6.070   Median :1.910   Median :57.65  
#  Mean   : 6.024   Mean   :1.976   Mean   :57.10  
#  3rd Qu.: 7.080   3rd Qu.:2.223   3rd Qu.:72.70  
#  Max.   :10.300   Max.   :2.480   Max.   :93.10</code></pre>
<pre class="r"><code>data %&gt;% 
  group_by(Temperature) %&gt;% 
  summarise(Mean_dry_weight = mean(Dry.weight), 
            Mean_optical_density = mean(Optical.density),
            Mean_product_yield = mean(Product.yield))</code></pre>
<pre><code># # A tibble: 3 × 4
#   Temperature Mean_dry_weight Mean_optical_density Mean_product_yield
#   &lt;fct&gt;                 &lt;dbl&gt;                &lt;dbl&gt;              &lt;dbl&gt;
# 1 30                     5.92                 1.92               56.6
# 2 35                     5.93                 1.99               56.5
# 3 37                     6.22                 2.01               58.3</code></pre>
</div>
<div id="hypothesis-1" class="section level2">
<h2>Hypothesis</h2>
<p><span class="math inline">\(H_0:\)</span> There is no significant difference in the average levels of dry weight, optical density, and product yield among two treatment groups.</p>
</div>
<div id="manova" class="section level2">
<h2>MANOVA</h2>
<pre class="r"><code>manova_result &lt;- manova(cbind(Dry.weight, Optical.density, Product.yield) ~ Temperature,
                        data = data)
summary(manova_result, test = &quot;Pillai&quot;)</code></pre>
<pre><code>#              Df   Pillai approx F num Df den Df Pr(&gt;F)
# Temperature   2 0.030774  0.60427      6    232 0.7268
# Residuals   117</code></pre>
<pre class="r"><code>summary(manova_result, test = &quot;Wilks&quot;)</code></pre>
<pre><code>#              Df   Wilks approx F num Df den Df Pr(&gt;F)
# Temperature   2 0.96939  0.60053      6    230 0.7298
# Residuals   117</code></pre>
<pre class="r"><code>summary(manova_result, test = &quot;Hotelling-Lawley&quot;)</code></pre>
<pre><code>#              Df Hotelling-Lawley approx F num Df den Df Pr(&gt;F)
# Temperature   2         0.031409  0.59677      6    228 0.7328
# Residuals   117</code></pre>
<pre class="r"><code>summary(manova_result, test = &quot;Roy&quot;)</code></pre>
<pre><code>#              Df      Roy approx F num Df den Df Pr(&gt;F)
# Temperature   2 0.024543  0.94899      3    116 0.4195
# Residuals   117</code></pre>
<p>A p-value lower than 0.05 means the null hypothesis can be rejected.</p>
<pre class="python"><code>import pandas as pd
from statsmodels.multivariate.manova import MANOVA

# Load the data
data = pd.read_table(&quot;data/MANOVA.txt&quot;, sep=&quot;\t&quot;)

# Perform MANOVA analysis
# Change variable names
new_column_names = {
    &#39;Dry weight&#39;: &#39;Weight&#39;,
    &#39;Optical density&#39;: &#39;Density&#39;,
    &#39;Product yield&#39;: &#39;Yield&#39;
}
data = data.rename(columns=new_column_names)
manova_result = MANOVA.from_formula(&#39;Weight + Density + Yield ~ Temperature&#39;, data)
print(manova_result.mv_test()) </code></pre>
<pre><code>#                   Multivariate linear model
# =============================================================
#                                                              
# -------------------------------------------------------------
#        Intercept        Value  Num DF  Den DF  F Value Pr &gt; F
# -------------------------------------------------------------
#           Wilks&#39; lambda 0.8059 3.0000 116.0000  9.3151 0.0000
#          Pillai&#39;s trace 0.1941 3.0000 116.0000  9.3151 0.0000
#  Hotelling-Lawley trace 0.2409 3.0000 116.0000  9.3151 0.0000
#     Roy&#39;s greatest root 0.2409 3.0000 116.0000  9.3151 0.0000
# -------------------------------------------------------------
#                                                              
# -------------------------------------------------------------
#       Temperature       Value  Num DF  Den DF  F Value Pr &gt; F
# -------------------------------------------------------------
#           Wilks&#39; lambda 0.9771 3.0000 116.0000  0.9079 0.4396
#          Pillai&#39;s trace 0.0229 3.0000 116.0000  0.9079 0.4396
#  Hotelling-Lawley trace 0.0235 3.0000 116.0000  0.9079 0.4396
#     Roy&#39;s greatest root 0.0235 3.0000 116.0000  0.9079 0.4396
# =============================================================</code></pre>
<hr />
<p><strong>Refererences:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://online.stat.psu.edu/stat505/lesson/8">Stat PSU - Lesson 8: Multivariate Analysis of Variance (MANOVA)</a><br />
</li>
<li><a href="https://towardsdatascience.com/manova-97e675a96158">MANOVA, towards data science</a></li>
<li>P.K. Bhattacharya, Prabir Burman - Theory and Methods of Statistics<br />
</li>
<li><a href="https://www.chegg.com/homework-help/questions-and-answers/experiment-temperature-n-source-replica-dry-weight-optical-density-product-yield-batch30aa-q35487503">Data description</a><br />
</li>
<li><a href="https://www.applied-maths.com/download/sample-data">Data source</a><br />
</li>
<li>Applied MANOVA and Discriminant Analysis-Wiley-Interscience (2006)<br />
</li>
<li>Srivastava Multivariate Statistics - page 187</li>
</ol>
</div>
</div>
